# coffee_and_currency_rates_case

This is the repository for the Pismo Analytics Engineer case about currency rates and coffee values, and negotiated volume.

[Challenge link](https://docs.google.com/document/d/16WUlM6zMa0-3COcg6_ZD7mEScghxSeV_/edit?usp=sharing&ouid=103282881946233759113&rtpof=true&sd=true)

In this ReadMe I will describe the three parts of the project and the ideas behind each part.

The three parts are:

1- [Google Colab Notebook](https://colab.research.google.com/drive/10UjWRFmEKLRJOsiv3M9ysA1qv2dXpBiM?usp=sharing): where is the code developed to create the solution;

2- [Google Drive folder with the result of the SQL queries](https://drive.google.com/drive/folders/12wkbX4g3uu2yPfP5Qva9qCc3LWUbiqlr?usp=sharing): where is the result of the SQL queries in csv files;

3- [Dashboard with data visualizations](https://lookerstudio.google.com/reporting/50a4800b-3b88-44dd-97f0-c3ad37e31b35): the dashboard that contain the visualizations about the currency rates through time.

Observation: The Google Colab Notebook is versioned in this [link](https://github.com/marcelo-vitti/coffee_and_currency_rates_case/blob/main/notebooks/Pismo_Analytics_Engineer.ipynb) on this repository.

## 1- Google Colab Notebook

This [notebook](https://colab.research.google.com/drive/10UjWRFmEKLRJOsiv3M9ysA1qv2dXpBiM?usp=sharing) is holding all the Python code of the project, and it has some sections that I will describe their logic and how I imagine that it would work in production.

The sections are:

1.1- Get Currency Rates to SQLite Table;

1.2- Get Coffee to SQLite Table;

1.3- Get SQL Queries results;

1.4- Save SQL queries results in Google Drive.

### 1.1 - Get Currency Rates to SQLite Table

In this first section I am  making some calls (iterating a date range) to openexchangerates API (I am using that because it has a quota of 1000 requisitions per month, much more than the other one that was suggested). While making this calls, I am appending the desired content inside a dictionary. 

After all the calls (that are done in the specified range of the dates), I transform this dictionary into a dataframe and add some date flags about end of month and year (this will be used in the third part of the project, the dashboard).

With that dataframe ready, I transform it into a SQL statement using SQLite and create a table with this data.

### 1.2- Get Coffee to SQLite Table

This is a very simple section. I am reading the *coffee.csv* file from Github (it could be located in S3, Cloud Storage, or another storage service) on this [link](https://github.com/marcelo-vitti/coffee_and_currency_rates_case/blob/main/external_sources/coffee.csv). After that, I am creating and inserting this data into a new table.

### 1.3- Get SQL Queries results

Now I am opening the three SQL files located in Github that contains the SQL query responsible for answering the three questions present in the [challenge](https://docs.google.com/document/d/16WUlM6zMa0-3COcg6_ZD7mEScghxSeV_/edit#). After opening this files, I am querying the SQLite tables that I built in the previous step.

Questions:

> Maior volume negociado de café no dia e as cotações de fechamento

[Query link](https://github.com/marcelo-vitti/coffee_and_currency_rates_case/blob/main/sql/highest_coffee_volume_and_currency_closing.sql)

> Total de café negociado por ano e as cotações

[Query link](https://github.com/marcelo-vitti/coffee_and_currency_rates_case/blob/main/sql/coffee_per_year_and_rates.sql)

> Média de volume negociado mensal e anual 

[Query link](https://github.com/marcelo-vitti/coffee_and_currency_rates_case/blob/main/sql/negotiated_coffee_average.sql)

### 1.4- Save SQL queries results in Google Drive

Super simple section where I save the result of the queries inside the Google Drive because it was one of the requirements.

### Diagram of possible workflow inside Airflow or other data pipeline tool:

<img width="872" alt="Screen Shot 2023-03-30 at 13 12 19" src="https://user-images.githubusercontent.com/129317565/228899042-139216a7-abe1-48af-b56f-c55371de86ea.png">

## 2- Google Drive folder with the result of the SQL queries

The CSV files generated by  Google Colab Notebook are saved in this [Google Drive folder](https://drive.google.com/drive/folders/12wkbX4g3uu2yPfP5Qva9qCc3LWUbiqlr?usp=sharing) and can be checked if there is a need.

## 3- Dashboard with data visualizations

In this [dashboard](https://lookerstudio.google.com/reporting/50a4800b-3b88-44dd-97f0-c3ad37e31b35) I created some visualizations to show to the user information about the currency rates, and their behavior thought time.

I created a [datasource](https://lookerstudio.google.com/datasources/e135c086-1569-46cc-b736-2041b2028288) in Looker Studio to centralyze and be the only source of data of this dashboard.

The dashboard have three pages:

Page 1:

<img width="486" alt="Screen Shot 2023-03-30 at 13 17 22" src="https://user-images.githubusercontent.com/129317565/228900277-d4acd69a-4362-4a0c-9735-eb1116b728c4.png">
<img width="488" alt="Screen Shot 2023-03-30 at 13 17 28" src="https://user-images.githubusercontent.com/129317565/228900290-a63c145b-ce40-40ec-97c3-065de4956754.png">

On this page, we have the latest currency rate for the three currencies and we also have the monthly development of these currencies, I used a filter of the end of the month to get only the rate of the last day of the month.

Page 2 and 3:

On pages two and three we only have the yearly and daily vision of these currencies, we probably could change the order of these pages depending on witch vision is more important in the operation.
